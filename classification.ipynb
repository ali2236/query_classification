{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "285487e6",
   "metadata": {},
   "source": [
    "# IR Mini Project 2\n",
    "Ali Ghanbari - 970216657"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7149791a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "824ed107",
   "metadata": {},
   "source": [
    "1. Download dataset if necessery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb91f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-12-20 15:57:30--  ftp://https/\n",
      "           => '.listing'\n",
      "Resolving https (https)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'https'\n",
      "//: Scheme missing.\n",
      "--2022-12-20 15:57:36--  http://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
      "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label [following]\n",
      "--2022-12-20 15:57:37--  https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 335858 (328K)\n",
      "Saving to: 'train_5500.label.1'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 15% 38.0M 0s\n",
      "    50K .......... .......... .......... .......... .......... 30% 74.5M 0s\n",
      "   100K .......... .......... .......... .......... .......... 45% 53.0M 0s\n",
      "   150K .......... .......... .......... .......... .......... 60%  938K 0s\n",
      "   200K .......... .......... .......... .......... .......... 76%  203K 0s\n",
      "   250K .......... .......... .......... .......... .......... 91%  360K 0s\n",
      "   300K .......... .......... .......                         100%  248K=0.6s\n",
      "\n",
      "2022-12-20 15:57:40 (592 KB/s) - 'train_5500.label.1' saved [335858/335858]\n",
      "\n",
      "--2022-12-20 15:57:40--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:57:43--  http://o/\n",
      "Resolving o (o)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'o'\n",
      "--2022-12-20 15:57:45--  http://train.txt/\n",
      "Resolving train.txt (train.txt)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'train.txt'\n",
      "--2022-12-20 15:57:45--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:57:48--  http://nc/\n",
      "Resolving nc (nc)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'nc'\n",
      "FINISHED --2022-12-20 15:57:51--\n",
      "Total wall clock time: 21s\n",
      "Downloaded: 1 files, 328K in 0.6s (592 KB/s)\n",
      "--2022-12-20 15:57:51--  ftp://https/\n",
      "           => '.listing'\n",
      "Resolving https (https)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'https'\n",
      "//: Scheme missing.\n",
      "--2022-12-20 15:57:54--  http://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
      "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label [following]\n",
      "--2022-12-20 15:57:54--  https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23354 (23K)\n",
      "Saving to: 'TREC_10.label'\n",
      "\n",
      "     0K .......... .......... ..                              100% 30.1M=0.001s\n",
      "\n",
      "2022-12-20 15:57:56 (30.1 MB/s) - 'TREC_10.label' saved [23354/23354]\n",
      "\n",
      "--2022-12-20 15:57:56--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:57:58--  http://o/\n",
      "Resolving o (o)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'o'\n",
      "--2022-12-20 15:58:01--  http://test.txt/\n",
      "Resolving test.txt (test.txt)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'test.txt'\n",
      "--2022-12-20 15:58:01--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:58:04--  http://nc/\n",
      "Resolving nc (nc)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'nc'\n",
      "FINISHED --2022-12-20 15:58:07--\n",
      "Total wall clock time: 16s\n",
      "Downloaded: 1 files, 23K in 0.001s (30.1 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label - O train.txt - nc\n",
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label - O test.txt - nc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60331ff8",
   "metadata": {},
   "source": [
    "2. Define text preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcebe9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75888408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(txt: str) -> str:\n",
    "    tokens = word_tokenize(txt)\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokens = [w for w in tokens if w not in english_stopwords]\n",
    "    # tokens = [stemmer.stem(w) for w in tokens]\n",
    "    # tokens = [lemma.lemmatize(w, pos = \"v\") for w in tokens]\n",
    "    # tokens = [lemma.lemmatize(w, pos = \"n\") for w in tokens]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba75ddad",
   "metadata": {},
   "source": [
    "3. Define data parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data(parent class, child class, query, vector)\n",
    "from typing import Iterable\n",
    "class QueryRow:\n",
    "    def __init__(self, parent_class : str, child_class : str, query: str, vector) -> None:\n",
    "        self.parent_class = parent_class\n",
    "        self.child_class = child_class\n",
    "        self.query = query\n",
    "        self.vector = vector\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.parent_class}:{self.child_class} {self.query} - {self.vector}'\n",
    "        \n",
    "\n",
    "def parse_line(line) -> QueryRow:\n",
    "    spline = line.split()\n",
    "    labels = spline[0]\n",
    "    text = spline[1:-1]\n",
    "    splbl = labels.split(':')\n",
    "    parent_class = splbl[0]\n",
    "    child_class = splbl[1]\n",
    "    query = preprocess_text(' '.join(text))\n",
    "    return QueryRow(parent_class, child_class, query, [])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07df2fdf",
   "metadata": {},
   "source": [
    "4. Load and preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3691d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DESC:manner serfdom develop leave russia - [],\n",
       " ENTY:cremat films featured character popeye doyle - [],\n",
       " DESC:manner find list celebrities real names - [],\n",
       " ENTY:animal fowl grabs spotlight chinese year monkey - [],\n",
       " ABBR:exp full form - [],\n",
       " HUM:ind contemptible scoundrel stole cork lunch - [],\n",
       " HUM:gr team baseball louis browns become - [],\n",
       " HUM:title oldest profession - [],\n",
       " DESC:def liver enzymes - [],\n",
       " HUM:ind name bounty hunter old west - [],\n",
       " NUM:date ozzy osbourne born - [],\n",
       " DESC:reason heavier objects travel downhill faster - []]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "with open('train.txt') as f:\n",
    "    train_data = [parse_line(line) for line in f.readlines() if line]\n",
    "with open('test.txt') as f:\n",
    "    test_data = [parse_line(line) for line in f.readlines() if line]\n",
    "train_data[:12]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fede7a",
   "metadata": {},
   "source": [
    "5. Vectorieze queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132d9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DESC:manner serfdom develop leave russia -   (0, 6507)\t1\n",
       "   (0, 2025)\t1\n",
       "   (0, 4124)\t1\n",
       "   (0, 6315)\t1,\n",
       " ENTY:cremat films featured character popeye doyle -   (0, 2754)\t1\n",
       "   (0, 2698)\t1\n",
       "   (0, 1267)\t1\n",
       "   (0, 5633)\t1\n",
       "   (0, 2208)\t1,\n",
       " DESC:manner find list celebrities real names -   (0, 2759)\t1\n",
       "   (0, 4231)\t1\n",
       "   (0, 1215)\t1\n",
       "   (0, 5989)\t1\n",
       "   (0, 4887)\t1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_data = train_data + test_data\n",
    "all_queries = [d.query for d in all_data]\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "queries = count_vect.fit_transform(all_queries)\n",
    "\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "    row = all_data[i]\n",
    "    row.vector = queries[i]\n",
    "\n",
    "all_data[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320dd827",
   "metadata": {},
   "source": [
    "---\n",
    "# Single Level Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4357c9",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6bcc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 8152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def make_2d(arr):\n",
    "    nsamples, nx, ny = arr.shape\n",
    "    return arr.reshape((nsamples,nx*ny))\n",
    "\n",
    "train_x = make_2d(np.array([q.vector.toarray() for q in train_data]))\n",
    "train_y = [q.parent_class for q in train_data]\n",
    "test_x = make_2d(np.array([q.vector.toarray() for q in test_data]))\n",
    "test_y = [q.parent_class for q in test_data]\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fcd3f64",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c890887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# benchmark(name, accuracy macro, accuracy micro, precision macro, precision micro, recall macro, recall micro, time train, time test)\n",
    "\n",
    "\n",
    "def benchmark_single_class(classifier, name: str) -> tuple[str, float, float, float, float, float, float, float, float]:\n",
    "    train_start = time.process_time()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    train_end = time.process_time()\n",
    "    train_time = train_end - train_start\n",
    "    test_start = time.process_time()\n",
    "    test_pred = classifier.predict(test_x)\n",
    "    test_end = time.process_time()\n",
    "    test_time = test_end - test_start\n",
    "    acc = accuracy_score(test_y, test_pred),\n",
    "    pre_macro = precision_score(test_y, test_pred, average='macro', zero_division=1)\n",
    "    pre_micro = precision_score(test_y, test_pred, average='micro', zero_division=1)\n",
    "    rec_macro = recall_score(test_y, test_pred, average='macro', zero_division=1)\n",
    "    rec_micro = recall_score(test_y, test_pred, average='micro', zero_division=1)\n",
    "    return (name, acc, acc, pre_macro, pre_micro, rec_macro, rec_micro, train_time, test_time)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd88cde6",
   "metadata": {},
   "source": [
    "1. Naïve Bayes(Bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b26ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "sc_bnb_results = benchmark_single_class(bnb, 'Naïve Bayes(Bernoulli)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8373d55c",
   "metadata": {},
   "source": [
    "2. Naïve Bayes(Multinomial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2955176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "sc_mnb_results = benchmark_single_class(mnb, 'Naïve Bayes(Multinomial)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb1b84c",
   "metadata": {},
   "source": [
    "3. KNN(k=3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b56f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn3 = KNeighborsClassifier(3)\n",
    "sc_knn3_results = benchmark_single_class(knn3, 'KNN(k=3)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33358d72",
   "metadata": {},
   "source": [
    "4. KNN(k=4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab92f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn4 = KNeighborsClassifier(4)\n",
    "sc_knn4_results = benchmark_single_class(knn4, 'KNN(k=4)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ec1201",
   "metadata": {},
   "source": [
    "5. KNN(k=5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1238e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn5 = KNeighborsClassifier(5)\n",
    "sc_knn5_results = benchmark_single_class(knn5, 'KNN(k=5)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ece4473",
   "metadata": {},
   "source": [
    "6. SVM(Gaussian kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87d5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmg = SVC(kernel='rbf')\n",
    "sc_svmg_results = benchmark_single_class(svmg, 'SVM(Gaussian kernel)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8954babb",
   "metadata": {},
   "source": [
    "7. SVM(Linear kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd36928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svml = SVC(kernel='linear')\n",
    "sc_svml_results = benchmark_single_class(svml, 'SVM(Linear kernel)[libsvm]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921ab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svml2 = LinearSVC()\n",
    "sc_svml2_results = benchmark_single_class(svml2, 'SVM(Linear kernel)[liblinear]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14dea4c",
   "metadata": {},
   "source": [
    "### Evaluation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c83062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy macro</th>\n",
       "      <th>accuracy micro</th>\n",
       "      <th>precision macro</th>\n",
       "      <th>precision micro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>recall micro</th>\n",
       "      <th>time train</th>\n",
       "      <th>time test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes(Bernoulli)</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.564411</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.487898</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naïve Bayes(Multinomial)</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.692718</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN(k=3)</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.701188</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.398801</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN(k=4)</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.758205</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.411082</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN(k=5)</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.760255</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.351494</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM(Gaussian kernel)</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.805937</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.721637</td>\n",
       "      <td>0.732</td>\n",
       "      <td>37.15625</td>\n",
       "      <td>1.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM(Linear kernel)[libsvm]</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.743710</td>\n",
       "      <td>0.754</td>\n",
       "      <td>34.06250</td>\n",
       "      <td>5.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM(Linear kernel)[liblinear]</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.794668</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  accuracy macro  accuracy micro  \\\n",
       "0         Naïve Bayes(Bernoulli)           0.596           0.596   \n",
       "1       Naïve Bayes(Multinomial)           0.720           0.720   \n",
       "2                       KNN(k=3)           0.398           0.398   \n",
       "3                       KNN(k=4)           0.400           0.400   \n",
       "4                       KNN(k=5)           0.374           0.374   \n",
       "5           SVM(Gaussian kernel)           0.732           0.732   \n",
       "6     SVM(Linear kernel)[libsvm]           0.754           0.754   \n",
       "7  SVM(Linear kernel)[liblinear]           0.752           0.752   \n",
       "\n",
       "   precision macro  precision micro  recall macro  recall micro  time train  \\\n",
       "0         0.564411            0.596      0.487898         0.596     0.00000   \n",
       "1         0.753000            0.720      0.692718         0.720     0.09375   \n",
       "2         0.701188            0.398      0.398801         0.398     0.00000   \n",
       "3         0.758205            0.400      0.411082         0.400     0.00000   \n",
       "4         0.760255            0.374      0.351494         0.374     0.00000   \n",
       "5         0.805937            0.732      0.721637         0.732    37.15625   \n",
       "6         0.794515            0.754      0.743710         0.754    34.06250   \n",
       "7         0.794668            0.752      0.745614         0.752     0.18750   \n",
       "\n",
       "   time test  \n",
       "0   0.062500  \n",
       "1   0.000000  \n",
       "2   2.781250  \n",
       "3   2.984375  \n",
       "4   2.921875  \n",
       "5   1.218750  \n",
       "6   5.156250  \n",
       "7   0.046875  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sc_df = pd.DataFrame(data=[sc_bnb_results, sc_mnb_results, sc_knn3_results, sc_knn4_results, sc_knn5_results, sc_svmg_results, sc_svml_results, sc_svml2_results],\n",
    "                     columns=['name', 'accuracy macro', 'accuracy micro', 'precision macro', 'precision micro', 'recall macro', 'recall micro', 'time train', 'time test'])\n",
    "\n",
    "sc_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58072d39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2 Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35fd45f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC()\n",
    "lsvm.fit(train_x, train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb83ee6e",
   "metadata": {},
   "source": [
    ". Group data by parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a119f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "for row in train_data:\n",
    "    sub_data[row.parent_class].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b1a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sub_classifiers = {\n",
    "    'ABBR' : LinearSVC(),\n",
    "    'DESC' : LinearSVC(),\n",
    "    'ENTY' : LinearSVC(),\n",
    "    'HUM' : LinearSVC(),\n",
    "    'LOC' : LinearSVC(),\n",
    "    'NUM' : LinearSVC(),\n",
    "}\n",
    "\n",
    "for parent_class, classifier in sub_classifiers.items():\n",
    "    rows = sub_data[parent_class]\n",
    "    data = make_2d(np.array([q.vector.toarray() for q in rows]))\n",
    "    labels = [q.child_class for q in rows]\n",
    "    classifier.fit(data, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8452ed3a",
   "metadata": {},
   "source": [
    ". Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1723eae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NUM', 'LOC', 'DESC', 'DESC', 'LOC', 'NUM', 'HUM', 'DESC', 'DESC',\n",
       "       'DESC'], dtype='<U4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_parent_classes = lsvm.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, predicted_parent_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80cc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test_x = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "sub_test_y = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    vector = test_x[i]\n",
    "    sub_class = test_data[i].child_class\n",
    "    predicted_parent_class = predicted_parent_classes[i]\n",
    "    sub_test_x[predicted_parent_class].append(vector)\n",
    "    sub_test_y[predicted_parent_class].append(sub_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d169ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m parent_class, queries \u001b[39min\u001b[39;00m sub_test_x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      4\u001b[0m     classifier \u001b[39m=\u001b[39m sub_classifiers[parent_class]\n\u001b[1;32m----> 5\u001b[0m     sub_pred_test_y[parent_class] \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mpredict(queries)\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m parent_class, pred_y \u001b[39min\u001b[39;00m sub_pred_test_y\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(classification_report(sub_test_y[parent_class], pred_y, zero_division\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:420\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 420\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    422\u001b[0m     indices \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    398\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    399\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 401\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    402\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[0;32m    403\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39mreshape(scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 900\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    901\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    902\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    905\u001b[0m         )\n\u001b[0;32m    907\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "sub_pred_test_y = {}\n",
    "\n",
    "for parent_class, queries in sub_test_x.items():\n",
    "    classifier = sub_classifiers[parent_class]\n",
    "    sub_pred_test_y[parent_class] = classifier.predict(queries)\n",
    "\n",
    "for parent_class, pred_y in sub_pred_test_y.items():\n",
    "    print(classification_report(sub_test_y[parent_class], pred_y, zero_division=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02c5fff5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64e1f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_train_rows = sub_data['LOC']\n",
    "location_train_x = make_2d(np.array([q.vector.toarray() for q in location_train_rows]))\n",
    "location_train_y = [q.child_class for q in location_train_rows]\n",
    "\n",
    "location_test_x = sub_test_x['LOC']\n",
    "location_test_y = sub_test_y['LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0798d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3: -0.051448443314693004\n",
      "k=4: -0.051448443314693004\n",
      "k=5: -0.03340588561034041\n",
      "k=6: -0.03340588561034041\n",
      "k=7: -0.0284506687336597\n",
      "k=8: -0.00889370443526024\n",
      "k=9: -0.00889370443526024\n",
      "k=10: -0.00889370443526024\n",
      "k=11: -0.002947261005390069\n",
      "k=12: -0.002947261005390069\n",
      "k=13: 0.0023993693060671553\n",
      "k=14: -0.045595166946979133\n",
      "k=15: -0.030291352791638405\n",
      "k=16: -0.030291352791638405\n",
      "k=17: -0.030291352791638405\n",
      "k=18: -0.030291352791638405\n",
      "k=19: -0.038760515014475284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "cluster_size_variants = range(3, 20)\n",
    "\n",
    "for n_clusters in cluster_size_variants:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\")\n",
    "    kmeans.fit(location_train_x, location_train_y)\n",
    "    location_pred_y = kmeans.predict(location_test_x)\n",
    "    score = silhouette_score(location_test_x, location_pred_y)\n",
    "    print(f'k={n_clusters}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e0b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4ea2e4b26b0fd95219da9fe00dd3bb328c5d875c7deaef4b029faf977d454da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
