{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "285487e6",
   "metadata": {},
   "source": [
    "# IR Mini Project 2\n",
    "Ali Ghanbari - 970216657"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7149791a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "824ed107",
   "metadata": {},
   "source": [
    "1. Download dataset if necessery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb91f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-12-20 14:03:11--  ftp://https/\n",
      "           => '.listing'\n",
      "Resolving https (https)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'https'\n",
      "//: Scheme missing.\n",
      "--2022-12-20 14:03:16--  http://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
      "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Hotspot login required\n",
      "Location: http://dorm.net/login?dst=http%3A%2F%2Fcogcomp.seas.upenn.edu%2FData%2FQA%2FQC%2Ftrain%5F5500.label [following]\n",
      "--2022-12-20 14:03:20--  http://dorm.net/login?dst=http%3A%2F%2Fcogcomp.seas.upenn.edu%2FData%2FQA%2FQC%2Ftrain_5500.label\n",
      "Resolving dorm.net (dorm.net)... 172.16.1.1\n",
      "Connecting to dorm.net (dorm.net)|172.16.1.1|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10694 (10K) [text/html]\n",
      "Saving to: 'train_5500.label.1'\n",
      "\n",
      "     0K ..........                                            100% 29.5M=0s\n",
      "\n",
      "2022-12-20 14:03:20 (29.5 MB/s) - 'train_5500.label.1' saved [10694/10694]\n",
      "\n",
      "--2022-12-20 14:03:20--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 14:03:22--  http://o/\n",
      "Resolving o (o)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'o'\n",
      "--2022-12-20 14:03:29--  http://train.txt/\n",
      "Resolving train.txt (train.txt)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'train.txt'\n",
      "--2022-12-20 14:03:29--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 14:03:31--  http://nc/\n",
      "Resolving nc (nc)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'nc'\n",
      "FINISHED --2022-12-20 14:03:34--\n",
      "Total wall clock time: 23s\n",
      "Downloaded: 1 files, 10K in 0s (29.5 MB/s)\n",
      "--2022-12-20 14:03:34--  ftp://https/\n",
      "           => '.listing'\n",
      "Resolving https (https)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'https'\n",
      "//: Scheme missing.\n",
      "--2022-12-20 14:03:37--  http://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
      "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Hotspot login required\n",
      "Location: http://dorm.net/login?dst=http%3A%2F%2Fcogcomp.seas.upenn.edu%2FData%2FQA%2FQC%2FTREC%5F10.label [following]\n",
      "--2022-12-20 14:03:37--  http://dorm.net/login?dst=http%3A%2F%2Fcogcomp.seas.upenn.edu%2FData%2FQA%2FQC%2FTREC_10.label\n",
      "Resolving dorm.net (dorm.net)... 172.16.1.1\n",
      "Connecting to dorm.net (dorm.net)|172.16.1.1|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10688 (10K) [text/html]\n",
      "Saving to: 'TREC_10.label.1'\n",
      "\n",
      "     0K ..........                                            100% 11.6M=0.001s\n",
      "\n",
      "2022-12-20 14:03:37 (11.6 MB/s) - 'TREC_10.label.1' saved [10688/10688]\n",
      "\n",
      "--2022-12-20 14:03:37--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 14:03:40--  http://o/\n",
      "Resolving o (o)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'o'\n",
      "--2022-12-20 14:03:42--  http://test.txt/\n",
      "Resolving test.txt (test.txt)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'test.txt'\n",
      "--2022-12-20 14:03:43--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 14:03:45--  http://nc/\n",
      "Resolving nc (nc)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'nc'\n",
      "FINISHED --2022-12-20 14:03:48--\n",
      "Total wall clock time: 14s\n",
      "Downloaded: 1 files, 10K in 0.001s (11.6 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label - O train.txt - nc\n",
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label - O test.txt - nc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60331ff8",
   "metadata": {},
   "source": [
    "2. Define text preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dcebe9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75888408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(txt: str) -> str:\n",
    "    tokens = word_tokenize(txt)\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokens = [w for w in tokens if w not in english_stopwords]\n",
    "    # tokens = [stemmer.stem(w) for w in tokens]\n",
    "    # tokens = [lemma.lemmatize(w, pos = \"v\") for w in tokens]\n",
    "    # tokens = [lemma.lemmatize(w, pos = \"n\") for w in tokens]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba75ddad",
   "metadata": {},
   "source": [
    "3. Define data parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc0fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data(parent class, child class, query, vector)\n",
    "from typing import Iterable\n",
    "class QueryRow:\n",
    "    def __init__(self, parent_class : str, child_class : str, query: str, vector) -> None:\n",
    "        self.parent_class = parent_class\n",
    "        self.child_class = child_class\n",
    "        self.query = query\n",
    "        self.vector = vector\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.parent_class}:{self.child_class} {self.query} - {self.vector}'\n",
    "        \n",
    "\n",
    "def parse_line(line) -> QueryRow:\n",
    "    spline = line.split()\n",
    "    labels = spline[0]\n",
    "    text = spline[1:-1]\n",
    "    splbl = labels.split(':')\n",
    "    parent_class = splbl[0]\n",
    "    child_class = splbl[1]\n",
    "    query = preprocess_text(' '.join(text))\n",
    "    return QueryRow(parent_class, child_class, query, [])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07df2fdf",
   "metadata": {},
   "source": [
    "4. Load and preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c3691d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DESC:manner serfdom develop leave russia - [],\n",
       " ENTY:cremat films featured character popeye doyle - [],\n",
       " DESC:manner find list celebrities real names - [],\n",
       " ENTY:animal fowl grabs spotlight chinese year monkey - [],\n",
       " ABBR:exp full form - [],\n",
       " HUM:ind contemptible scoundrel stole cork lunch - [],\n",
       " HUM:gr team baseball louis browns become - [],\n",
       " HUM:title oldest profession - [],\n",
       " DESC:def liver enzymes - [],\n",
       " HUM:ind name bounty hunter old west - [],\n",
       " NUM:date ozzy osbourne born - [],\n",
       " DESC:reason heavier objects travel downhill faster - []]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "with open('train.txt') as f:\n",
    "    train_data = [parse_line(line) for line in f.readlines() if line]\n",
    "with open('test.txt') as f:\n",
    "    test_data = [parse_line(line) for line in f.readlines() if line]\n",
    "train_data[:12]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fede7a",
   "metadata": {},
   "source": [
    "5. Vectorieze queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "132d9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DESC:manner serfdom develop leave russia -   (0, 6507)\t1\n",
       "   (0, 2025)\t1\n",
       "   (0, 4124)\t1\n",
       "   (0, 6315)\t1,\n",
       " ENTY:cremat films featured character popeye doyle -   (0, 2754)\t1\n",
       "   (0, 2698)\t1\n",
       "   (0, 1267)\t1\n",
       "   (0, 5633)\t1\n",
       "   (0, 2208)\t1,\n",
       " DESC:manner find list celebrities real names -   (0, 2759)\t1\n",
       "   (0, 4231)\t1\n",
       "   (0, 1215)\t1\n",
       "   (0, 5989)\t1\n",
       "   (0, 4887)\t1]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_data = train_data + test_data\n",
    "all_queries = [d.query for d in all_data]\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "queries = count_vect.fit_transform(all_queries)\n",
    "\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "    row = all_data[i]\n",
    "    row.vector = queries[i]\n",
    "\n",
    "all_data[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320dd827",
   "metadata": {},
   "source": [
    "---\n",
    "# Single Level Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4357c9",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9c6bcc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 8152)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def make_2d(arr):\n",
    "    nsamples, nx, ny = arr.shape\n",
    "    return arr.reshape((nsamples,nx*ny))\n",
    "\n",
    "train_x = make_2d(np.array([q.vector.toarray() for q in train_data]))\n",
    "train_y = [q.parent_class for q in train_data]\n",
    "test_x = make_2d(np.array([q.vector.toarray() for q in test_data]))\n",
    "test_y = [q.parent_class for q in test_data]\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fcd3f64",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c890887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# benchmark(name, accuracy macro, accuracy micro, precision macro, precision micro, recall macro, recall micro, time train, time test)\n",
    "\n",
    "\n",
    "def benchmark_single_class(classifier, name: str) -> tuple[str, float, float, float, float, float, float, float, float]:\n",
    "    train_start = time.process_time()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    train_end = time.process_time()\n",
    "    train_time = train_end - train_start\n",
    "    test_start = time.process_time()\n",
    "    test_pred = classifier.predict(test_x)\n",
    "    test_end = time.process_time()\n",
    "    test_time = test_end - test_start\n",
    "    acc = accuracy_score(test_y, test_pred)\n",
    "    pre_macro = precision_score(test_y, test_pred, average='macro')\n",
    "    pre_micro = precision_score(test_y, test_pred, average='micro')\n",
    "    rec_macro = recall_score(test_y, test_pred, average='macro')\n",
    "    rec_micro = recall_score(test_y, test_pred, average='micro')\n",
    "    return (name, acc, acc, pre_macro, pre_micro, rec_macro, rec_micro, train_time, test_time)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd88cde6",
   "metadata": {},
   "source": [
    "1. Naïve Bayes(Bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7b26ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Naïve Bayes(Bernoulli)',\n",
       " 0.596,\n",
       " 0.596,\n",
       " 0.5644107684430265,\n",
       " 0.596,\n",
       " 0.4878980286859022,\n",
       " 0.596,\n",
       " 0.21875,\n",
       " 0.0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "sc_bnb_results = benchmark_single_class(bnb, 'Naïve Bayes(Bernoulli)')\n",
    "sc_bnb_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8373d55c",
   "metadata": {},
   "source": [
    "2. Naïve Bayes(Multinomial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2955176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "sc_mnb_results = benchmark_single_class(mnb, 'Naïve Bayes(Multinomial)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb1b84c",
   "metadata": {},
   "source": [
    "3. KNN(k=3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b56f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn3 = KNeighborsClassifier(3)\n",
    "sc_knn3_results = benchmark_single_class(knn3, 'KNN(k=3)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33358d72",
   "metadata": {},
   "source": [
    "4. KNN(k=4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab92f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn4 = KNeighborsClassifier(4)\n",
    "sc_knn4_results = benchmark_single_class(knn4, 'KNN(k=4)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ec1201",
   "metadata": {},
   "source": [
    "5. KNN(k=5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1238e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn5 = KNeighborsClassifier(5)\n",
    "sc_knn5_results = benchmark_single_class(knn5, 'KNN(k=5)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ece4473",
   "metadata": {},
   "source": [
    "6. SVM(Gaussian kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d87d5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmg = SVC(kernel='rbf')\n",
    "sc_svmg_results = benchmark_single_class(svmg, 'SVM(Gaussian kernel)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8954babb",
   "metadata": {},
   "source": [
    "7. SVM(Linear kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dd36928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svml = SVC(kernel='linear')\n",
    "sc_svml_results = benchmark_single_class(svml, 'SVM(Linear kernel)[libsvm]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "921ab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svml2 = LinearSVC()\n",
    "sc_svml2_results = benchmark_single_class(svml2, 'SVM(Linear kernel)[liblinear]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14dea4c",
   "metadata": {},
   "source": [
    "### Evaluation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c83062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy macro</th>\n",
       "      <th>accuracy micro</th>\n",
       "      <th>precision macro</th>\n",
       "      <th>precision micro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>recall micro</th>\n",
       "      <th>time train</th>\n",
       "      <th>time test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes(Bernoulli)</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.564411</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.487898</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naïve Bayes(Multinomial)</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.692718</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN(k=3)</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.701188</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.398801</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN(k=4)</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.758205</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.411082</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN(k=5)</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.760255</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.351494</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM(Gaussian kernel)</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.805937</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.721637</td>\n",
       "      <td>0.732</td>\n",
       "      <td>45.453125</td>\n",
       "      <td>4.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM(Linear kernel)[libsvm]</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.743710</td>\n",
       "      <td>0.754</td>\n",
       "      <td>33.578125</td>\n",
       "      <td>1.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM(Linear kernel)[liblinear]</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.794668</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  accuracy macro  accuracy micro  \\\n",
       "0         Naïve Bayes(Bernoulli)           0.596           0.596   \n",
       "1       Naïve Bayes(Multinomial)           0.720           0.720   \n",
       "2                       KNN(k=3)           0.398           0.398   \n",
       "3                       KNN(k=4)           0.400           0.400   \n",
       "4                       KNN(k=5)           0.374           0.374   \n",
       "5           SVM(Gaussian kernel)           0.732           0.732   \n",
       "6     SVM(Linear kernel)[libsvm]           0.754           0.754   \n",
       "7  SVM(Linear kernel)[liblinear]           0.752           0.752   \n",
       "\n",
       "   precision macro  precision micro  recall macro  recall micro  time train  \\\n",
       "0         0.564411            0.596      0.487898         0.596    0.359375   \n",
       "1         0.753000            0.720      0.692718         0.720    0.375000   \n",
       "2         0.701188            0.398      0.398801         0.398    0.000000   \n",
       "3         0.758205            0.400      0.411082         0.400    0.000000   \n",
       "4         0.760255            0.374      0.351494         0.374    0.000000   \n",
       "5         0.805937            0.732      0.721637         0.732   45.453125   \n",
       "6         0.794515            0.754      0.743710         0.754   33.578125   \n",
       "7         0.794668            0.752      0.745614         0.752    0.140625   \n",
       "\n",
       "   time test  \n",
       "0   0.000000  \n",
       "1   0.015625  \n",
       "2   3.250000  \n",
       "3   3.234375  \n",
       "4   3.234375  \n",
       "5   4.781250  \n",
       "6   1.109375  \n",
       "7   0.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sc_df = pd.DataFrame(data=[sc_bnb_results, sc_mnb_results, sc_knn3_results, sc_knn4_results, sc_knn5_results, sc_svmg_results, sc_svml_results, sc_svml2_results],\n",
    "                     columns=['name', 'accuracy macro', 'accuracy micro', 'precision macro', 'precision micro', 'recall macro', 'recall micro', 'time train', 'time test'])\n",
    "\n",
    "sc_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58072d39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2 Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "35fd45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.72      0.91      0.80       138\n",
      "        ENTY       0.80      0.67      0.73        94\n",
      "         HUM       0.62      0.80      0.70        65\n",
      "         LOC       0.69      0.63      0.66        81\n",
      "         NUM       0.94      0.69      0.80       113\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.79      0.75      0.76       500\n",
      "weighted avg       0.77      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC()\n",
    "lsvm.fit(train_x, train_y)\n",
    "lsvm_pred = lsvm.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y, lsvm_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb83ee6e",
   "metadata": {},
   "source": [
    ". Group data by parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a119f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "for row in train_data:\n",
    "    sub_data[row.parent_class].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "69b1a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sub_classifiers = {\n",
    "    'ABBR' : LinearSVC(),\n",
    "    'DESC' : LinearSVC(),\n",
    "    'ENTY' : LinearSVC(),\n",
    "    'HUM' : LinearSVC(),\n",
    "    'LOC' : LinearSVC(),\n",
    "    'NUM' : LinearSVC(),\n",
    "}\n",
    "\n",
    "for parent_class, classifier in sub_classifiers.items():\n",
    "    rows = sub_data[parent_class]\n",
    "    data = make_2d(np.array([q.vector.toarray() for q in rows]))\n",
    "    labels = [q.child_class for q in rows]\n",
    "    classifier.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1723eae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02c5fff5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afd5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4ea2e4b26b0fd95219da9fe00dd3bb328c5d875c7deaef4b029faf977d454da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
