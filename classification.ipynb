{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "285487e6",
   "metadata": {},
   "source": [
    "# IR Mini Project 2\n",
    "Ali Ghanbari - 970216657"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7149791a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "824ed107",
   "metadata": {},
   "source": [
    "1. Download dataset if necessery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb91f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-12-20 15:57:30--  ftp://https/\n",
      "           => '.listing'\n",
      "Resolving https (https)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'https'\n",
      "//: Scheme missing.\n",
      "--2022-12-20 15:57:36--  http://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
      "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label [following]\n",
      "--2022-12-20 15:57:37--  https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 335858 (328K)\n",
      "Saving to: 'train_5500.label.1'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 15% 38.0M 0s\n",
      "    50K .......... .......... .......... .......... .......... 30% 74.5M 0s\n",
      "   100K .......... .......... .......... .......... .......... 45% 53.0M 0s\n",
      "   150K .......... .......... .......... .......... .......... 60%  938K 0s\n",
      "   200K .......... .......... .......... .......... .......... 76%  203K 0s\n",
      "   250K .......... .......... .......... .......... .......... 91%  360K 0s\n",
      "   300K .......... .......... .......                         100%  248K=0.6s\n",
      "\n",
      "2022-12-20 15:57:40 (592 KB/s) - 'train_5500.label.1' saved [335858/335858]\n",
      "\n",
      "--2022-12-20 15:57:40--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:57:43--  http://o/\n",
      "Resolving o (o)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'o'\n",
      "--2022-12-20 15:57:45--  http://train.txt/\n",
      "Resolving train.txt (train.txt)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'train.txt'\n",
      "--2022-12-20 15:57:45--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:57:48--  http://nc/\n",
      "Resolving nc (nc)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'nc'\n",
      "FINISHED --2022-12-20 15:57:51--\n",
      "Total wall clock time: 21s\n",
      "Downloaded: 1 files, 328K in 0.6s (592 KB/s)\n",
      "--2022-12-20 15:57:51--  ftp://https/\n",
      "           => '.listing'\n",
      "Resolving https (https)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'https'\n",
      "//: Scheme missing.\n",
      "--2022-12-20 15:57:54--  http://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
      "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label [following]\n",
      "--2022-12-20 15:57:54--  https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
      "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23354 (23K)\n",
      "Saving to: 'TREC_10.label'\n",
      "\n",
      "     0K .......... .......... ..                              100% 30.1M=0.001s\n",
      "\n",
      "2022-12-20 15:57:56 (30.1 MB/s) - 'TREC_10.label' saved [23354/23354]\n",
      "\n",
      "--2022-12-20 15:57:56--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:57:58--  http://o/\n",
      "Resolving o (o)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'o'\n",
      "--2022-12-20 15:58:01--  http://test.txt/\n",
      "Resolving test.txt (test.txt)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'test.txt'\n",
      "--2022-12-20 15:58:01--  http://-/\n",
      "Resolving - (-)... failed: No such host is known. .\n",
      "wget: unable to resolve host address '-'\n",
      "--2022-12-20 15:58:04--  http://nc/\n",
      "Resolving nc (nc)... failed: No such host is known. .\n",
      "wget: unable to resolve host address 'nc'\n",
      "FINISHED --2022-12-20 15:58:07--\n",
      "Total wall clock time: 16s\n",
      "Downloaded: 1 files, 23K in 0.001s (30.1 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label - O train.txt - nc\n",
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label - O test.txt - nc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60331ff8",
   "metadata": {},
   "source": [
    "2. Define text preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcebe9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75888408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(txt: str) -> str:\n",
    "    tokens = word_tokenize(txt)\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokens = [w for w in tokens if w not in english_stopwords]\n",
    "    # tokens = [stemmer.stem(w) for w in tokens]\n",
    "    # tokens = [lemma.lemmatize(w, pos = \"v\") for w in tokens]\n",
    "    # tokens = [lemma.lemmatize(w, pos = \"n\") for w in tokens]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba75ddad",
   "metadata": {},
   "source": [
    "3. Define data parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data(parent class, child class, query, vector)\n",
    "from typing import Iterable\n",
    "class QueryRow:\n",
    "    def __init__(self, parent_class : str, child_class : str, query: str, vector) -> None:\n",
    "        self.parent_class = parent_class\n",
    "        self.child_class = child_class\n",
    "        self.query = query\n",
    "        self.vector = vector\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.parent_class}:{self.child_class} {self.query} - {self.vector}'\n",
    "        \n",
    "\n",
    "def parse_line(line) -> QueryRow:\n",
    "    spline = line.split()\n",
    "    labels = spline[0]\n",
    "    text = spline[1:-1]\n",
    "    splbl = labels.split(':')\n",
    "    parent_class = splbl[0]\n",
    "    child_class = splbl[1]\n",
    "    query = preprocess_text(' '.join(text))\n",
    "    return QueryRow(parent_class, child_class, query, [])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07df2fdf",
   "metadata": {},
   "source": [
    "4. Load and preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3691d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DESC:manner serfdom develop leave russia - [],\n",
       " ENTY:cremat films featured character popeye doyle - [],\n",
       " DESC:manner find list celebrities real names - [],\n",
       " ENTY:animal fowl grabs spotlight chinese year monkey - [],\n",
       " ABBR:exp full form - [],\n",
       " HUM:ind contemptible scoundrel stole cork lunch - [],\n",
       " HUM:gr team baseball louis browns become - [],\n",
       " HUM:title oldest profession - [],\n",
       " DESC:def liver enzymes - [],\n",
       " HUM:ind name bounty hunter old west - [],\n",
       " NUM:date ozzy osbourne born - [],\n",
       " DESC:reason heavier objects travel downhill faster - []]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "with open('train.txt') as f:\n",
    "    train_data = [parse_line(line) for line in f.readlines() if line]\n",
    "with open('test.txt') as f:\n",
    "    test_data = [parse_line(line) for line in f.readlines() if line]\n",
    "train_data[:12]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fede7a",
   "metadata": {},
   "source": [
    "5. Vectorieze queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132d9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DESC:manner serfdom develop leave russia -   (0, 6507)\t1\n",
       "   (0, 2025)\t1\n",
       "   (0, 4124)\t1\n",
       "   (0, 6315)\t1,\n",
       " ENTY:cremat films featured character popeye doyle -   (0, 2754)\t1\n",
       "   (0, 2698)\t1\n",
       "   (0, 1267)\t1\n",
       "   (0, 5633)\t1\n",
       "   (0, 2208)\t1,\n",
       " DESC:manner find list celebrities real names -   (0, 2759)\t1\n",
       "   (0, 4231)\t1\n",
       "   (0, 1215)\t1\n",
       "   (0, 5989)\t1\n",
       "   (0, 4887)\t1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_data = train_data + test_data\n",
    "all_queries = [d.query for d in all_data]\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "queries = count_vect.fit_transform(all_queries)\n",
    "\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "    row = all_data[i]\n",
    "    row.vector = queries[i]\n",
    "\n",
    "all_data[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320dd827",
   "metadata": {},
   "source": [
    "---\n",
    "# Single Level Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4357c9",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6bcc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 8152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def make_2d(arr):\n",
    "    nsamples, nx, ny = arr.shape\n",
    "    return arr.reshape((nsamples,nx*ny))\n",
    "\n",
    "train_x = make_2d(np.array([q.vector.toarray() for q in train_data]))\n",
    "train_y = [q.parent_class for q in train_data]\n",
    "test_x = make_2d(np.array([q.vector.toarray() for q in test_data]))\n",
    "test_y = [q.parent_class for q in test_data]\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fcd3f64",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c890887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# benchmark(name, accuracy macro, accuracy micro, precision macro, precision micro, recall macro, recall micro, time train, time test)\n",
    "\n",
    "\n",
    "def benchmark_single_class(classifier, name: str) -> tuple[str, float, float, float, float, float, float, float, float]:\n",
    "    train_start = time.process_time()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    train_end = time.process_time()\n",
    "    train_time = train_end - train_start\n",
    "    test_start = time.process_time()\n",
    "    test_pred = classifier.predict(test_x)\n",
    "    test_end = time.process_time()\n",
    "    test_time = test_end - test_start\n",
    "    acc = accuracy_score(test_y, test_pred)\n",
    "    pre_macro = precision_score(test_y, test_pred, average='macro')\n",
    "    pre_micro = precision_score(test_y, test_pred, average='micro')\n",
    "    rec_macro = recall_score(test_y, test_pred, average='macro')\n",
    "    rec_micro = recall_score(test_y, test_pred, average='micro')\n",
    "    return (name, acc, acc, pre_macro, pre_micro, rec_macro, rec_micro, train_time, test_time)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd88cde6",
   "metadata": {},
   "source": [
    "1. Naïve Bayes(Bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b26ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Naïve Bayes(Bernoulli)',\n",
       " 0.596,\n",
       " 0.596,\n",
       " 0.5644107684430265,\n",
       " 0.596,\n",
       " 0.4878980286859022,\n",
       " 0.596,\n",
       " 0.0,\n",
       " 0.0625)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "sc_bnb_results = benchmark_single_class(bnb, 'Naïve Bayes(Bernoulli)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8373d55c",
   "metadata": {},
   "source": [
    "2. Naïve Bayes(Multinomial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2955176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "sc_mnb_results = benchmark_single_class(mnb, 'Naïve Bayes(Multinomial)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb1b84c",
   "metadata": {},
   "source": [
    "3. KNN(k=3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b56f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn3 = KNeighborsClassifier(3)\n",
    "sc_knn3_results = benchmark_single_class(knn3, 'KNN(k=3)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33358d72",
   "metadata": {},
   "source": [
    "4. KNN(k=4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab92f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn4 = KNeighborsClassifier(4)\n",
    "sc_knn4_results = benchmark_single_class(knn4, 'KNN(k=4)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ec1201",
   "metadata": {},
   "source": [
    "5. KNN(k=5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1238e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn5 = KNeighborsClassifier(5)\n",
    "sc_knn5_results = benchmark_single_class(knn5, 'KNN(k=5)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ece4473",
   "metadata": {},
   "source": [
    "6. SVM(Gaussian kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87d5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmg = SVC(kernel='rbf')\n",
    "sc_svmg_results = benchmark_single_class(svmg, 'SVM(Gaussian kernel)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8954babb",
   "metadata": {},
   "source": [
    "7. SVM(Linear kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd36928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svml = SVC(kernel='linear')\n",
    "sc_svml_results = benchmark_single_class(svml, 'SVM(Linear kernel)[libsvm]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921ab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svml2 = LinearSVC()\n",
    "sc_svml2_results = benchmark_single_class(svml2, 'SVM(Linear kernel)[liblinear]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14dea4c",
   "metadata": {},
   "source": [
    "### Evaluation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c83062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy macro</th>\n",
       "      <th>accuracy micro</th>\n",
       "      <th>precision macro</th>\n",
       "      <th>precision micro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>recall micro</th>\n",
       "      <th>time train</th>\n",
       "      <th>time test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes(Bernoulli)</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.564411</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.487898</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naïve Bayes(Multinomial)</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.692718</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN(k=3)</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.701188</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.398801</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN(k=4)</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.758205</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.411082</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN(k=5)</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.760255</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.351494</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM(Gaussian kernel)</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.805937</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.721637</td>\n",
       "      <td>0.732</td>\n",
       "      <td>37.15625</td>\n",
       "      <td>1.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM(Linear kernel)[libsvm]</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.743710</td>\n",
       "      <td>0.754</td>\n",
       "      <td>34.06250</td>\n",
       "      <td>5.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM(Linear kernel)[liblinear]</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.794668</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  accuracy macro  accuracy micro  \\\n",
       "0         Naïve Bayes(Bernoulli)           0.596           0.596   \n",
       "1       Naïve Bayes(Multinomial)           0.720           0.720   \n",
       "2                       KNN(k=3)           0.398           0.398   \n",
       "3                       KNN(k=4)           0.400           0.400   \n",
       "4                       KNN(k=5)           0.374           0.374   \n",
       "5           SVM(Gaussian kernel)           0.732           0.732   \n",
       "6     SVM(Linear kernel)[libsvm]           0.754           0.754   \n",
       "7  SVM(Linear kernel)[liblinear]           0.752           0.752   \n",
       "\n",
       "   precision macro  precision micro  recall macro  recall micro  time train  \\\n",
       "0         0.564411            0.596      0.487898         0.596     0.00000   \n",
       "1         0.753000            0.720      0.692718         0.720     0.09375   \n",
       "2         0.701188            0.398      0.398801         0.398     0.00000   \n",
       "3         0.758205            0.400      0.411082         0.400     0.00000   \n",
       "4         0.760255            0.374      0.351494         0.374     0.00000   \n",
       "5         0.805937            0.732      0.721637         0.732    37.15625   \n",
       "6         0.794515            0.754      0.743710         0.754    34.06250   \n",
       "7         0.794668            0.752      0.745614         0.752     0.18750   \n",
       "\n",
       "   time test  \n",
       "0   0.062500  \n",
       "1   0.000000  \n",
       "2   2.781250  \n",
       "3   2.984375  \n",
       "4   2.921875  \n",
       "5   1.218750  \n",
       "6   5.156250  \n",
       "7   0.046875  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sc_df = pd.DataFrame(data=[sc_bnb_results, sc_mnb_results, sc_knn3_results, sc_knn4_results, sc_knn5_results, sc_svmg_results, sc_svml_results, sc_svml2_results],\n",
    "                     columns=['name', 'accuracy macro', 'accuracy micro', 'precision macro', 'precision micro', 'recall macro', 'recall micro', 'time train', 'time test'])\n",
    "\n",
    "sc_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58072d39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2 Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35fd45f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC()\n",
    "lsvm.fit(train_x, train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb83ee6e",
   "metadata": {},
   "source": [
    ". Group data by parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a119f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "for row in train_data:\n",
    "    sub_data[row.parent_class].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69b1a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sub_classifiers = {\n",
    "    'ABBR' : LinearSVC(),\n",
    "    'DESC' : LinearSVC(),\n",
    "    'ENTY' : LinearSVC(),\n",
    "    'HUM' : LinearSVC(),\n",
    "    'LOC' : LinearSVC(),\n",
    "    'NUM' : LinearSVC(),\n",
    "}\n",
    "\n",
    "for parent_class, classifier in sub_classifiers.items():\n",
    "    rows = sub_data[parent_class]\n",
    "    data = make_2d(np.array([q.vector.toarray() for q in rows]))\n",
    "    labels = [q.child_class for q in rows]\n",
    "    classifier.fit(data, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8452ed3a",
   "metadata": {},
   "source": [
    ". Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1723eae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NUM', 'LOC', 'DESC', 'DESC', 'LOC', 'NUM', 'HUM', 'DESC', 'DESC',\n",
       "       'DESC'], dtype='<U4')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_parent_classes = lsvm.predict(test_x)\n",
    "\n",
    "predicted_parent_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a727b342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.72      0.91      0.80       138\n",
      "        ENTY       0.80      0.67      0.73        94\n",
      "         HUM       0.62      0.80      0.70        65\n",
      "         LOC       0.69      0.63      0.66        81\n",
      "         NUM       0.94      0.69      0.80       113\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.79      0.75      0.76       500\n",
      "weighted avg       0.77      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predicted_parent_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d80cc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test_x = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "sub_test_y = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    vector = test_x[i]\n",
    "    sub_class = test_data[i].child_class\n",
    "    predicted_parent_class = predicted_parent_classes[i]\n",
    "    sub_test_x[predicted_parent_class].append(vector)\n",
    "    sub_test_y[predicted_parent_class].append(sub_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82d169ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abb       1.00      0.00      0.00         1\n",
      "         exp       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.93      0.50      0.46         7\n",
      "weighted avg       0.88      0.86      0.79         7\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      animal       1.00      0.00      0.00         1\n",
      "        city       1.00      0.00      0.00         3\n",
      "       color       1.00      0.00      0.00         1\n",
      "        date       1.00      0.00      0.00         6\n",
      "         def       0.72      0.99      0.83       114\n",
      "        desc       1.00      0.29      0.44         7\n",
      "        dist       1.00      0.00      0.00         2\n",
      "         exp       1.00      0.00      0.00         2\n",
      "         ind       1.00      0.00      0.00         4\n",
      "      manner       0.10      1.00      0.18         1\n",
      "       other       1.00      0.00      0.00        17\n",
      "      period       1.00      0.00      0.00         1\n",
      "       plant       1.00      0.00      0.00         1\n",
      "      reason       0.25      0.25      0.25         4\n",
      "       state       1.00      0.00      0.00         1\n",
      "   substance       1.00      0.00      0.00         6\n",
      "        temp       1.00      0.00      0.00         1\n",
      "         veh       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.68       173\n",
      "   macro avg       0.89      0.14      0.10       173\n",
      "weighted avg       0.79      0.68      0.57       173\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      animal       1.00      0.85      0.92        13\n",
      "        body       0.33      1.00      0.50         1\n",
      "        city       1.00      0.00      0.00         1\n",
      "       color       1.00      1.00      1.00         9\n",
      "      cremat       0.00      1.00      0.00         0\n",
      "    currency       0.75      1.00      0.86         6\n",
      "         def       1.00      0.00      0.00         6\n",
      "      dismed       0.50      1.00      0.67         1\n",
      "        dist       1.00      0.00      0.00         1\n",
      "        food       0.67      0.50      0.57         4\n",
      "         ind       1.00      0.00      0.00         1\n",
      "      instru       1.00      1.00      1.00         1\n",
      "        lang       1.00      1.00      1.00         2\n",
      "      manner       1.00      0.00      0.00         1\n",
      "       other       0.31      0.50      0.38         8\n",
      "       plant       1.00      1.00      1.00         1\n",
      "     product       1.00      1.00      1.00         1\n",
      "      reason       1.00      0.00      0.00         2\n",
      "       sport       1.00      1.00      1.00         1\n",
      "       state       1.00      0.00      0.00         1\n",
      "   substance       0.71      0.62      0.67         8\n",
      "    techmeth       1.00      1.00      1.00         1\n",
      "      termeq       0.60      0.86      0.71         7\n",
      "         veh       1.00      1.00      1.00         2\n",
      "        word       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68        79\n",
      "   macro avg       0.79      0.65      0.53        79\n",
      "weighted avg       0.81      0.68      0.66        79\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      animal       1.00      0.00      0.00         1\n",
      "        body       1.00      0.00      0.00         1\n",
      "        date       1.00      0.00      0.00         8\n",
      "         def       1.00      0.00      0.00         1\n",
      "        desc       1.00      0.00      0.00         2\n",
      "      dismed       1.00      0.00      0.00         1\n",
      "        dist       1.00      0.00      0.00         2\n",
      "       event       1.00      0.00      0.00         2\n",
      "          gr       0.60      0.60      0.60         5\n",
      "         ind       0.57      1.00      0.73        45\n",
      "       other       1.00      0.00      0.00        11\n",
      "      period       1.00      0.00      0.00         1\n",
      "     product       1.00      0.00      0.00         2\n",
      "       title       1.00      0.00      0.00         1\n",
      "         veh       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57        84\n",
      "   macro avg       0.94      0.11      0.09        84\n",
      "weighted avg       0.75      0.57      0.42        84\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      animal       1.00      0.00      0.00         1\n",
      "        city       1.00      0.86      0.92        14\n",
      "     country       1.00      1.00      1.00         3\n",
      "        date       1.00      0.00      0.00         5\n",
      "         def       1.00      0.00      0.00         1\n",
      "        desc       1.00      0.00      0.00         1\n",
      "        dist       1.00      0.00      0.00         4\n",
      "          gr       1.00      0.00      0.00         1\n",
      "         ind       1.00      0.00      0.00         4\n",
      "       money       1.00      0.00      0.00         1\n",
      "       mount       0.67      0.67      0.67         3\n",
      "       other       0.61      1.00      0.76        27\n",
      "       plant       1.00      0.00      0.00         3\n",
      "     product       1.00      0.00      0.00         1\n",
      "       state       0.33      1.00      0.50         4\n",
      "   substance       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.65        74\n",
      "   macro avg       0.91      0.28      0.24        74\n",
      "weighted avg       0.81      0.65      0.55        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       count       0.82      1.00      0.90         9\n",
      "        date       0.88      1.00      0.93        28\n",
      "         def       1.00      0.00      0.00         1\n",
      "        dist       1.00      1.00      1.00         7\n",
      "         ind       1.00      0.00      0.00         1\n",
      "       money       1.00      0.50      0.67         2\n",
      "       other       1.00      0.45      0.62        11\n",
      "        perc       0.75      1.00      0.86         3\n",
      "      period       0.67      1.00      0.80         6\n",
      "       speed       1.00      1.00      1.00         6\n",
      "       state       1.00      0.00      0.00         1\n",
      "        temp       1.00      1.00      1.00         4\n",
      "      weight       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.87        83\n",
      "   macro avg       0.91      0.67      0.66        83\n",
      "weighted avg       0.89      0.87      0.84        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_pred_test_y = {}\n",
    "\n",
    "for parent_class, queries in sub_test_x.items():\n",
    "    classifier = sub_classifiers[parent_class]\n",
    "    sub_pred_test_y[parent_class] = classifier.predict(queries)\n",
    "\n",
    "for parent_class, pred_y in sub_pred_test_y.items():\n",
    "    print(classification_report(sub_test_y[parent_class], pred_y, zero_division=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02c5fff5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afd5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4ea2e4b26b0fd95219da9fe00dd3bb328c5d875c7deaef4b029faf977d454da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
