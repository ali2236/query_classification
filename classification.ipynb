{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "285487e6",
   "metadata": {},
   "source": [
    "# IR Mini Project 2\n",
    "Ali Ghanbari - 40110524"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7149791a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "824ed107",
   "metadata": {},
   "source": [
    "1. Download dataset if necessery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb91f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'train.txt' already there; not retrieving.\n",
      "File 'test.txt' already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label -O train.txt -nc\n",
    "!wget https: // cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label -O test.txt -nc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60331ff8",
   "metadata": {},
   "source": [
    "2. Define text preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcebe9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aligator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75888408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "english_stopwords.remove('who')\n",
    "english_stopwords.remove('where')\n",
    "english_stopwords.remove('what')\n",
    "english_stopwords.remove('how')\n",
    "\n",
    "\n",
    "def preprocess_text(txt: str) -> str:\n",
    "    tokens = word_tokenize(txt)\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokens = [w for w in tokens if w not in english_stopwords]\n",
    "    tokens = [stemmer.stem(w) for w in tokens]\n",
    "    tokens = [lemma.lemmatize(w, pos = \"v\") for w in tokens]\n",
    "    tokens = [lemma.lemmatize(w, pos = \"n\") for w in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba75ddad",
   "metadata": {},
   "source": [
    "3. Define data parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data(parent class, child class, query, vector)\n",
    "from typing import Iterable\n",
    "class QueryRow:\n",
    "    def __init__(self, parent_class : str, child_class : str, query: str, vector) -> None:\n",
    "        self.parent_class = parent_class\n",
    "        self.child_class = child_class\n",
    "        self.query = query\n",
    "        self.vector = vector\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.parent_class}:{self.child_class} {self.query} - {self.vector}'\n",
    "        \n",
    "\n",
    "def parse_line(line) -> QueryRow:\n",
    "    spline = line.split()\n",
    "    labels = spline[0]\n",
    "    text = spline[1:-1]\n",
    "    splbl = labels.split(':')\n",
    "    parent_class = splbl[0]\n",
    "    child_class = splbl[1]\n",
    "    query = preprocess_text(' '.join(text))\n",
    "    return QueryRow(parent_class, child_class, query, [])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07df2fdf",
   "metadata": {},
   "source": [
    "4. Load and preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3691d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "with open('train.txt') as f:\n",
    "    train_data = [parse_line(line) for line in f.readlines() if line]\n",
    "with open('test.txt') as f:\n",
    "    test_data = [parse_line(line) for line in f.readlines() if line]\n",
    "\n",
    "# print empty queries\n",
    "empty_queries = list(filter(lambda q: not q.query,train_data))\n",
    "empty_queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fede7a",
   "metadata": {},
   "source": [
    "5. Vectorieze queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132d9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(sublinear_tf=False, use_idf=True, norm='l2')\n",
    "train_queries = tfidf_vec.fit([q.query for q in train_data])\n",
    "\n",
    "all_data = train_data + test_data\n",
    "for q in all_data:\n",
    "    q.vector = tfidf_vec.transform([q.query])[0]\n",
    "\n",
    "np.shape(all_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320dd827",
   "metadata": {},
   "source": [
    "---\n",
    "# Single Level Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4357c9",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6bcc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 6334)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def make_2d(arr):\n",
    "    nsamples, nx, ny = arr.shape\n",
    "    return arr.reshape((nsamples,nx*ny))\n",
    "\n",
    "train_x = make_2d(np.array([q.vector.toarray() for q in train_data]))\n",
    "train_y = [q.parent_class for q in train_data]\n",
    "test_x = make_2d(np.array([q.vector.toarray() for q in test_data]))\n",
    "test_y = [q.parent_class for q in test_data]\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fcd3f64",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c890887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def class_accuracy_score(true, pred, average=None):\n",
    "    class_preds_tp = {}\n",
    "    class_preds_fn = {}\n",
    "    for i in range(len(true)):\n",
    "        c = true[i]\n",
    "        p = pred[i]\n",
    "        if c == p:\n",
    "            class_preds_tp[c] = class_preds_tp.get(c, 0) + 1\n",
    "        else:\n",
    "            class_preds_fn[c] = class_preds_fn.get(c, 0) + 1\n",
    "    all_classes = set(class_preds_fn.keys()).union(class_preds_tp.keys())\n",
    "    class_accuracy = {}\n",
    "    for cls in all_classes:\n",
    "        tp = class_preds_tp.get(cls, 0)\n",
    "        fn = class_preds_fn.get(cls, 0)\n",
    "        class_accuracy[cls] = tp / (tp + fn)\n",
    "    if average == \"macro\":\n",
    "        return np.average(list(class_accuracy.values()))\n",
    "    elif average == \"micro\":\n",
    "        return (np.sum(list(class_preds_tp.values()))) / (np.sum(list(class_preds_tp.values())) + np.sum(list(class_preds_fn.values())))\n",
    "    return class_accuracy\n",
    "\n",
    "\n",
    "benchmark_results = {}\n",
    "# benchmark(name, accuracy macro, accuracy micro, precision macro, precision micro, recall macro, recall micro, time train, time test)\n",
    "def benchmark_single_class(classifier, name: str):\n",
    "    train_start = time.process_time()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    train_end = time.process_time()\n",
    "    train_time = train_end - train_start\n",
    "    test_start = time.process_time()\n",
    "    test_pred = classifier.predict(test_x)\n",
    "    test_end = time.process_time()\n",
    "    test_time = test_end - test_start\n",
    "    acc_macro = class_accuracy_score(test_y, test_pred, average=\"macro\")\n",
    "    acc_micro = class_accuracy_score(test_y, test_pred, average=\"micro\")\n",
    "    pre_macro = precision_score(test_y, test_pred, average='macro', zero_division=0)\n",
    "    pre_micro = precision_score(test_y, test_pred, average='micro', zero_division=0)\n",
    "    rec_macro = recall_score(test_y, test_pred, average='macro', zero_division=0)\n",
    "    rec_micro = recall_score(test_y, test_pred, average='micro', zero_division=0)\n",
    "    benchmark_results[name] = (name, acc_macro, acc_micro, pre_macro, pre_micro, rec_macro, rec_micro, train_time, test_time)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd88cde6",
   "metadata": {},
   "source": [
    "1. Naïve Bayes(Bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b26ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "benchmark_single_class(bnb, 'Naïve Bayes(Bernoulli)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8373d55c",
   "metadata": {},
   "source": [
    "2. Naïve Bayes(Multinomial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2955176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "benchmark_single_class(mnb, 'Naïve Bayes(Multinomial)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb1b84c",
   "metadata": {},
   "source": [
    "3. KNN(k=3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b56f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn3 = KNeighborsClassifier(3)\n",
    "benchmark_single_class(knn3, 'KNN(k=3)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33358d72",
   "metadata": {},
   "source": [
    "4. KNN(k=4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab92f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn4 = KNeighborsClassifier(4)\n",
    "benchmark_single_class(knn4, 'KNN(k=4)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ec1201",
   "metadata": {},
   "source": [
    "5. KNN(k=5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1238e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn5 = KNeighborsClassifier(5)\n",
    "benchmark_single_class(knn5, 'KNN(k=5)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ece4473",
   "metadata": {},
   "source": [
    "6. SVM(Gaussian kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87d5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmg = SVC(kernel='rbf')\n",
    "# benchmark_single_class(svmg, 'SVM(Gaussian kernel)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8954babb",
   "metadata": {},
   "source": [
    "7. SVM(Linear kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd36928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svml = SVC(kernel='linear')\n",
    "# benchmark_single_class(svml, 'SVM(Linear kernel)[libsvm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "921ab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svml2 = LinearSVC(max_iter=5000)\n",
    "benchmark_single_class(svml2, 'SVM(Linear kernel)[liblinear]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14dea4c",
   "metadata": {},
   "source": [
    "### Evaluation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38c83062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy macro</th>\n",
       "      <th>accuracy micro</th>\n",
       "      <th>precision macro</th>\n",
       "      <th>precision micro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>recall micro</th>\n",
       "      <th>time train</th>\n",
       "      <th>time test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes(Bernoulli)</td>\n",
       "      <td>0.553538</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.598048</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.553538</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naïve Bayes(Multinomial)</td>\n",
       "      <td>0.562244</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.549397</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.562244</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN(k=3)</td>\n",
       "      <td>0.636994</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.634042</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.636994</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN(k=4)</td>\n",
       "      <td>0.662911</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.669021</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.662911</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>4.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN(k=5)</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.717931</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.40625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM(Linear kernel)[liblinear]</td>\n",
       "      <td>0.818435</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.846587</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.818435</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  accuracy macro  accuracy micro  \\\n",
       "0         Naïve Bayes(Bernoulli)        0.553538           0.652   \n",
       "1       Naïve Bayes(Multinomial)        0.562244           0.608   \n",
       "2                       KNN(k=3)        0.636994           0.622   \n",
       "3                       KNN(k=4)        0.662911           0.650   \n",
       "4                       KNN(k=5)        0.694293           0.688   \n",
       "5  SVM(Linear kernel)[liblinear]        0.818435           0.818   \n",
       "\n",
       "   precision macro  precision micro  recall macro  recall micro  time train  \\\n",
       "0         0.598048            0.652      0.553538         0.652    0.281250   \n",
       "1         0.549397            0.608      0.562244         0.608    0.093750   \n",
       "2         0.634042            0.622      0.636994         0.622    0.000000   \n",
       "3         0.669021            0.650      0.662911         0.650    0.125000   \n",
       "4         0.717931            0.688      0.694293         0.688    0.015625   \n",
       "5         0.846587            0.818      0.818435         0.818    0.093750   \n",
       "\n",
       "   time test  \n",
       "0    0.00000  \n",
       "1    0.00000  \n",
       "2    5.34375  \n",
       "3    4.84375  \n",
       "4    4.40625  \n",
       "5    0.00000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sc_df = pd.DataFrame(data=list(benchmark_results.values()),\n",
    "                     columns=['name', 'accuracy macro', 'accuracy micro', 'precision macro', 'precision micro', 'recall macro', 'recall micro', 'time train', 'time test'])\n",
    "\n",
    "sc_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58072d39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2 Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35fd45f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(max_iter=5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC(max_iter=5000)\n",
    "lsvm.fit(train_x, train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb83ee6e",
   "metadata": {},
   "source": [
    ". Group data by parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a119f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "for row in train_data:\n",
    "    sub_data[row.parent_class].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b1a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sub_classifiers = {\n",
    "    'ABBR' : LinearSVC(max_iter=5000),\n",
    "    'DESC' : LinearSVC(max_iter=5000),\n",
    "    'ENTY' : LinearSVC(max_iter=5000),\n",
    "    'HUM' : LinearSVC(max_iter=5000),\n",
    "    'LOC' : LinearSVC(max_iter=5000),\n",
    "    'NUM' : LinearSVC(max_iter=5000),\n",
    "}\n",
    "\n",
    "for parent_class, classifier in sub_classifiers.items():\n",
    "    rows = sub_data[parent_class]\n",
    "    data = make_2d(np.array([q.vector.toarray() for q in rows]))\n",
    "    labels = [q.child_class for q in rows]\n",
    "    classifier.fit(data, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8452ed3a",
   "metadata": {},
   "source": [
    ". Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1723eae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABBR</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTY</th>\n",
       "      <th>HUM</th>\n",
       "      <th>LOC</th>\n",
       "      <th>NUM</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804054</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.846587</td>\n",
       "      <td>0.825276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.818435</td>\n",
       "      <td>0.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.871166</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.826529</td>\n",
       "      <td>0.817484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ABBR        DESC       ENTY        HUM        LOC         NUM  \\\n",
       "precision  1.000000    0.804054   0.707865   0.756098   0.865854    0.945652   \n",
       "recall     0.777778    0.862319   0.670213   0.953846   0.876543    0.769912   \n",
       "f1-score   0.875000    0.832168   0.688525   0.843537   0.871166    0.848780   \n",
       "support    9.000000  138.000000  94.000000  65.000000  81.000000  113.000000   \n",
       "accuracy   0.777778    0.862319   0.670213   0.953846   0.876543    0.769912   \n",
       "\n",
       "           accuracy   macro avg  weighted avg  \n",
       "precision     0.818    0.846587      0.825276  \n",
       "recall        0.818    0.818435      0.818000  \n",
       "f1-score      0.818    0.826529      0.817484  \n",
       "support       0.818  500.000000    500.000000  \n",
       "accuracy      0.818         NaN           NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "predicted_parent_classes = lsvm.predict(test_x)\n",
    "\n",
    "parent_results = classification_report(test_y, predicted_parent_classes, zero_division=0, output_dict=True)\n",
    "p_acc = class_accuracy_score(test_y, predicted_parent_classes)\n",
    "for cls, acc in p_acc.items():\n",
    "    parent_results[cls]['accuracy'] = acc\n",
    "\n",
    "parants_df = pd.DataFrame.from_dict(parent_results)\n",
    "parants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d80cc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test_x = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "sub_test_y = {\n",
    "    'ABBR' : [],\n",
    "    'DESC' : [],\n",
    "    'ENTY' : [],\n",
    "    'HUM' : [],\n",
    "    'LOC' : [],\n",
    "    'NUM' : [],\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    vector = test_x[i]\n",
    "    sub_class = test_data[i].child_class\n",
    "    predicted_parent_class = predicted_parent_classes[i]\n",
    "    sub_test_x[predicted_parent_class].append(vector)\n",
    "    sub_test_y[predicted_parent_class].append(sub_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82d169ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parent Class</th>\n",
       "      <th>Child Class</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBR</td>\n",
       "      <td>abb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBR</td>\n",
       "      <td>exp</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DESC</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DESC</td>\n",
       "      <td>date</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESC</td>\n",
       "      <td>def</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NUM</td>\n",
       "      <td>reason</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NUM</td>\n",
       "      <td>speed</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NUM</td>\n",
       "      <td>state</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NUM</td>\n",
       "      <td>temp</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NUM</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parent Class Child Class  Accuracy  Precision    Recall  Support\n",
       "0          ABBR         abb  0.000000   0.000000  0.000000        1\n",
       "1          ABBR         exp  1.000000   0.857143  1.000000        6\n",
       "2          DESC      animal  0.000000   0.000000  0.000000        2\n",
       "3          DESC        date  0.000000   0.000000  0.000000        3\n",
       "4          DESC         def  0.990909   0.865079  0.990909      110\n",
       "..          ...         ...       ...        ...       ...      ...\n",
       "73          NUM      reason  0.000000   0.000000  0.000000        1\n",
       "74          NUM       speed  0.800000   1.000000  0.800000        5\n",
       "75          NUM       state  0.000000   0.000000  0.000000        1\n",
       "76          NUM        temp  1.000000   1.000000  1.000000        4\n",
       "77          NUM      weight  0.750000   1.000000  0.750000        4\n",
       "\n",
       "[78 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, precision_score, classification_report\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import pandas as pd\n",
    "\n",
    "sub_pred_test_y = {}\n",
    "sub_rows = []\n",
    "\n",
    "for parent_class, queries in sub_test_x.items():\n",
    "    classifier = sub_classifiers[parent_class]\n",
    "    sub_pred_test_y[parent_class] = classifier.predict(queries)\n",
    "\n",
    "for parent_class, pred_y in sub_pred_test_y.items():\n",
    "    accuracy = class_accuracy_score(sub_test_y[parent_class], pred_y)\n",
    "    labels = unique_labels(sub_test_y[parent_class], pred_y)\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(sub_test_y[parent_class], pred_y, zero_division=0,)\n",
    "    rows = list(zip([parent_class for p in range(len(labels))], labels, [accuracy.get(lbl, -1) for lbl in labels], precision, recall, support))\n",
    "    sub_rows = sub_rows + rows\n",
    "\n",
    "sub_df = pd.DataFrame(data=sub_rows, columns=['Parent Class', 'Child Class', 'Accuracy', 'Precision', 'Recall', 'Support'])\n",
    "sub_df.to_csv('sub_classes.csv')\n",
    "sub_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02c5fff5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_train_rows = sub_data['LOC']\n",
    "location_train_x = make_2d(np.array([q.vector.toarray() for q in location_train_rows]))\n",
    "location_train_y = [q.child_class for q in location_train_rows]\n",
    "\n",
    "location_test_x = sub_test_x['LOC']\n",
    "location_test_y = sub_test_y['LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "def cluster_precision(labels_x, cluster_x, cluster_y):\n",
    "    \"\"\"returns lebels_y\"\"\"\n",
    "    classifier = LinearSVC(max_iter=3000)\n",
    "    transformer = {}\n",
    "    i = 0\n",
    "    for label in set(labels_x):\n",
    "        transformer[label] = i\n",
    "        i = i + 1\n",
    "    reverse_transform = {transformer[key]: key for key in transformer.keys()}\n",
    "    labels_x_vec = list(map(lambda l: transformer[l], labels_x))\n",
    "    classifier.fit(np.array(cluster_x).reshape(-1, 1), labels_x_vec)\n",
    "    labels_y_vec = classifier.predict(np.array(cluster_y).reshape(-1, 1))\n",
    "    labels_y = [reverse_transform[v] for v in labels_y_vec]\n",
    "    return labels_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0798d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k=3</th>\n",
       "      <th>k=4</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=6</th>\n",
       "      <th>k=7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.219697</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.219697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.172996</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.093532</td>\n",
       "      <td>0.172996</td>\n",
       "      <td>0.096264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_index</th>\n",
       "      <td>0.533875</td>\n",
       "      <td>0.618187</td>\n",
       "      <td>0.695875</td>\n",
       "      <td>0.684734</td>\n",
       "      <td>0.730503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette</th>\n",
       "      <td>0.051324</td>\n",
       "      <td>0.062125</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.076049</td>\n",
       "      <td>0.112966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 k=3       k=4       k=5       k=6       k=7\n",
       "recall      0.222222  0.111111  0.219697  0.222222  0.219697\n",
       "precision   0.172996  0.059621  0.093532  0.172996  0.096264\n",
       "rand_index  0.533875  0.618187  0.695875  0.684734  0.730503\n",
       "silhouette  0.051324  0.062125  0.074700  0.076049  0.112966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, recall_score, precision_score, rand_score\n",
    "import pandas as pd \n",
    "\n",
    "kmeans_results = {}\n",
    "for n_clusters in range(3, 8):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=100, max_iter=3000)\n",
    "    cluster_x = kmeans.fit_predict(location_train_x)\n",
    "    location_pred_y = kmeans.predict(location_test_x)\n",
    "    labels_y = cluster_precision(location_train_y, cluster_x, location_pred_y)\n",
    "    kmeans_results[f'k={n_clusters}'] = {\n",
    "        'recall' : recall_score(location_test_y, labels_y, average=\"macro\", zero_division=0),\n",
    "        'precision' : precision_score(location_test_y, labels_y, average=\"macro\", zero_division=0),\n",
    "        'rand_index' : rand_score(location_test_y, location_pred_y),\n",
    "        'silhouette' : silhouette_score(location_test_x, location_pred_y),\n",
    "    }\n",
    "kmeans_df = pd.DataFrame(kmeans_results)\n",
    "kmeans_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4ea2e4b26b0fd95219da9fe00dd3bb328c5d875c7deaef4b029faf977d454da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
